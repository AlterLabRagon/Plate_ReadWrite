---
title: "Guide to Using Plate_ReadWrite to Format IQue Data"
date: "08/14/2022"
output:
  html_document:
    df_print: paged
---

### Before Getting Started

#### Install Packages
Before getting started with Plate_ReadWrite, make sure you have installed the following packages. You can install them using the following command: ``` install.packages(c("readr","tidyr","dplyr","ggplot2","plater","tibble","stats","devtools"))```. You only need to do this step once. To access the packages later, you will store them in your library.

#### Gather and Format Your Input Data
To run plate_readwrite, you will need a platemap, iQue data, sample annotation, and plate annotation. You can skip providing sample and plate annotation data files.

1. The **platemap** has spatially mapped out unique identifiers or index values
    - Rows are labeled A - H or A - P depending on whether it is a 96 or 384 Well Plate
    - Columns are labeled 1 - 12 or 1 - 24
    - There is a space between each row
    - You can find a template of the platemap [here](https://github.com/AlterLabRagon/Plate_ReadWrite/tree/main/Example/Template) 


2. The **sample annotation data** contains additional information about each sample that is organized by its unique identifier or index #
    - The annotated column needs to contain an **unique_id** column


3. The **iQue Experimental Data**, which is in long format (not plate format)
    - The iQue data has a row starting with "Plate: " separating data from each plate
  
  
4. The **plate annotation data** describes the secondaries, beadsets, and sample arrangements used in each experimental plate. You can see an example [here](https://github.com/AlterLabRagon/Plate_ReadWrite/tree/main/Example/Template).
    - The plate annotation data file needs to have **plate**, **platemap**, **set**, and **secondary** columns that account for each experimental plate run.
 
 
#### Download the code
1. You can either (1) download the entire folder from the [GitHub](https://github.com/AlterLabRagon/Plate_ReadWrite) by clicking on the green code button and selecting download zip or (2) copying and pasting the main script found [here](https://github.com/AlterLabRagon/Plate_ReadWrite/blob/main/User_friendly_version.R) into a new R script. If you choose to download the entire folder, you can double click on the User_friendly_version_new.R script to change the working directory to that folder. 


### Inputs
First, we specify required inputs.
```{r}
exp_name <- 'Bead_party'
num_384 <- 4
num_96 <- 0
num_well_in_platemap <- 96
duplicate_horizontal <- TRUE 
measurements <- NULL
save_path <- 'Plate_ReadWrite_Results/'
```
We can either specify the file path or leave it as null to be prompted with a pop up window.
```{r}
sample_annotation_path <- 'Example/Data/sample_annotation_data.csv'
platemap_path <- 'Example/Data/platemap_small.csv'
plate_annotation_path <- 'Example/Data/plate_annotation_small.csv'
IQue_path <- 'Example/Data/ique_data.csv'
skip_sample_annotation <- FALSE
skip_plate_annotation <- FALSE
```
Here are optional parameters you can set. If you choose to skip providing a plate annotation file, you must enter the name of the secondary used and the number of plate maps found in the platemap file. You can also change the minimum bead count or plot correlations here.
```{r}
QC_min_bead_count <- NULL
plot_corr <- NULL
secondary_name <- NULL
num_platemap <- NULL
```
This code chunk prompts you with a pop up window if the file paths were set to be NULL.
```{r}
if(is.null(sample_annotation_path))
  {sample_annotation_path = rstudioapi::selectFile(caption = "Select Sample Annotation Data File",label = "Select Sample Annotation Data File",filter = "CSV Files (*.csv)",existing = TRUE)}
if(is.null(platemap_path))
  {platemap_path <- rstudioapi::selectFile(caption = "Select Platemap File",label = "Select Platemap File",filter = "CSV Files (*.csv)",existing = TRUE)}
if(is.null(plate_annotation_path))
  {plate_annotation_path <- rstudioapi::selectFile(caption = "Select Plate Annotation File",label = "Select Plate Annotation File",filter = "CSV Files (*.csv)",existing = TRUE)}
if(is.null(IQue_path))
  {IQue_path <- rstudioapi::selectFile(caption = "Select iQue Data File",label = "Select iQue Data File",filter = "CSV Files (*.csv)",existing = TRUE)}
```
This code assigns values to the optional parameters if they were set to be null. By default, the minimum bead threshold is set to 40 and no correlation plots are produced.
```{r}
# If no plate names are provided, integer names will be assigned to the plates
plate_names <- NULL
if(is.null(plate_names))
  {actual_num_plate <- ifelse(num_96 == 0, num_384, num_96)
  plate_names <- c(1:actual_num_plate)}
# If no QC check is provided, a minimum bead count threshold of 20 is set
if(is.null(QC_min_bead_count))
  {QC_min_bead_count <- 40}
# If no option is provided for plotting correlation plot, it is set to FALSE
if(is.null(plot_corr))
  {plot_corr <- FALSE}
```
### Code to Run
This code adds the packages to the library, a specific directory where packages are stored. We also download source code files from GitHub. We also create a directory where resulting files are stored if the save_path is not found.
```{r}
library(readr)
library(tidyr)
library(dplyr)
library(ggplot2)
library(plater)
library(tibble)
library(stats)

source('Src/Format_checks2.R')
source('Src/convert_384..R')

# Creates a save_path directory 
if(!dir.exists(save_path))
  {dir.create(save_path,recursive = 'T')}
```
Here we create a logger file that stores messages and warnings received while running the project. Make sure you check the logger file for any warnings!
```{r}
dir.create(file.path(save_path,'Log'))
log_path <- file.path(save_path,'Log')
get_log_file_name <- function(file_name="log_file")
  {file_name <- paste(file_name,format(Sys.time(), "%X%Y%m%d"),sep="_")
  file_name <- paste(log_path, paste(file_name,"log", sep="."), sep="/")
  return(file_name)}
logger <- file(get_log_file_name(), open = "a")
sink(logger, append = TRUE, type="message")
```
We perform formatting checks to ensure that the files are compatible with the program requirements. If they are not compatible, you can fix the files as described by the warnings and change the file paths and rerun the code.
```{r}
check_sample_annotation_data(sample_annotation_path)
check_exp_data(IQue_path,measurements,num_384,num_96)
check_plater_format(platemap_path)
check_plate_annotation(plate_annotation_path)
```
If a plate annotation data file is not provided, we create data to match the experimental data provided.
```{r}
if(skip_plate_annotation)
  {secondary_name <- ifelse(is.null(secondary),1,secondary)
  rep_or_not <- ifelse(num_384 !=0 & num_well_in_platemap == 96,TRUE,FALSE)
  num_actual_plates <- ifelse(num_384 != 0,num_384,num_96)
  plate_rep <- ifelse(rep_or_not,2,1)
  bm_plate_list <- rep(c(1:num_actual_plates),each = plate_rep, length.out = num_actual_plates*plate_rep)
  bm_platemap_list <- rep(c(1:num_platemap),length.out = num_actual_plates*plate_rep)
  bm_beadtype_list <- rep(1,length.out = num_actual_plates*plate_rep)
  bm_secondary_list <-  rep(secondary_name,length.out = num_actual_plates*plate_rep)
  beadmap_data <- data.frame('plate' = bm_plate_list, 'platemap' = bm_platemap_list, 'set' = bm_beadtype_list, 'secondary' = bm_secondary_list)
}else{
  beadmap_data <- read_csv(plate_annotation_path)
}
head(beadmap_data,10)
```
We read in the plate annotation data data to identify the number of experimental plates, the number of platemap plates, beadtypes, and secondaries. 
```{r}
colnames(beadmap_data) <- tolower(colnames(beadmap_data))
platemap_col <- grep('platemap',colnames(beadmap_data))
num_exp <- length(unique(beadmap_data$plate))
num_platemap <- length(unique(beadmap_data$platemap))
num_beadtype <- length(unique(beadmap_data$set))
num_secondary <- length(unique(beadmap_data$secondary))
```
We double check that the platemap has either 96 or 384 wells and that the number of experimental data files only consist of 384 or 96-well plate data exclusively.
```{r}
if (!num_well_in_platemap %in% c(96, 384))
  {stop('The number of wells in the platemap must be 96 or 384')}
if (num_96 !=0 & num_384 !=0)
  {stop('You can only have 96 or 384 well plates in the data not both!')}
```

We check to make sure that the plate annotation data specifies all plates of interest.
```{r}
if (num_well_in_platemap == 384 & num_exp != num_platemap | num_well_in_platemap == 96 & num_exp != num_platemap*2 |num_well_in_platemap == 96 & num_exp != num_platemap)
  {check_mapping <- (num_exp == num_platemap * num_beadtype * num_secondary)
  check_mapping_w_d <- (num_exp == (num_platemap * num_beadtype * num_secondary) / 2)
    if (any(c(check_mapping,check_mapping_w_d) == TRUE))
      {platemap_list <- beadmap_data$platemap
      bead_names <- paste0('.',beadmap_data$set)
      secondary_names <- paste0('.',beadmap_data$secondary)}
    else
      {stop(paste0('The number of platemaps provided does not match number of experimental plates, considering the different bead sets and secondaries used.','\n Number of beadtypes: ',num_beadtype,'\n Number of secondaries: ',num_secondary,'\n Number of plates in the platemap: ',num_platemap,'\n Number of plates used experimentally: ',num_exp))}}
```
Sample annotation data is read. If the skip sample annotation data parameter is set to TRUE, fake annotation data is created.
```{r}
if(skip_sample_annotation == TRUE)
  {sample_meta_data <- data.frame(unique_id = c(1:50),fake_1 = rep(LETTERS[1:25],2),fake_2 = rep(c('A','B'),25))}
if(skip_sample_annotation == FALSE)
  {sample_meta_data <- read_csv(sample_annotation_path)}

colnames(sample_meta_data) <- tolower(colnames(sample_meta_data))
anno_col <- ncol(sample_meta_data) - 1
sample_meta_data$unique_id <- as.character(sample_meta_data$unique_id)
```
We read in the experimental data by finding the location of each row that starts with ‘Plate:’. The number of plates the user is interested in can be smaller or the same size as the number of plates found in the experimental data. We later combine data from the multiple plates and add in the plate names and numbers.
```{r}
# Setting the pattern that comes before the start of a new plate
plate.indic <- "Plate: "
# Read in the raw file
lines <- readLines(IQue_path)
# Find the start of the new plates using the plate.indic pattern
plate.start <- grep(plate.indic, lines)
# Get plate names that are listed in the experimental data file (1 plate name per row)
lines2 <- gsub('(^"|"$|,)', "", lines)
plate_names <- lines2[plate.start]
# Initialize the lists that will have the experiments, plate #, and plate names
exp_list <- list()
plate_list <- list()
plate_names_list <- list()
# Read experimental data from csv file when the number of plates the user is interested in is less than the # of plates found
if (num_384 + num_96 < length(plate.start))
  {actual_num_plate <- ifelse(num_96 == 0, num_384, num_96)
  for (i in c(1:actual_num_plate))
    {idx = plate.start[i] 
    exp_list[[i]] <- read.csv(IQue_path, skip=idx, header=TRUE,nrows=(plate.start[i+1] - plate.start[i] - 2))
    plate_list[[i]] <- rep(i,plate.start[i+1] - plate.start[i] - 2)
    plate_names_list[[i]] <- rep(plate_names[i],plate.start[i+1] - plate.start[i] - 2) } }
# Read experimental data from csv file when the number of plates the user is interested in is equal to the # of plates 
if (num_384 + num_96 == length(plate.start))
  {actual_num_plate <- ifelse(num_96 == 0, num_384, num_96)
  for (i in c(1:actual_num_plate))
    {if (i != actual_num_plate)
      {idx = plate.start[i] 
      exp_list[[i]] <- read.csv(IQue_path, skip=idx, header=TRUE,nrows=(plate.start[i+1] - plate.start[i] - 2))
      plate_list[[i]] <- rep(i,plate.start[i+1] - plate.start[i] - 2)
      plate_names_list[[i]] <- rep(plate_names[i],plate.start[i+1] - plate.start[i] - 2)}
    else
      {idx = plate.start[i] 
      exp_list[[i]] <- read.csv(IQue_path, skip=idx, header=TRUE)
      plate_list[[i]] <- rep(i,dim(exp_list[[i]])[1])
      plate_names_list[[i]] <- rep(plate_names[i],dim(exp_list[[i]])[1])}}}
# Outputs error when the number of plates the user is interested in is greater than the # of plates found
if (num_384 + num_96 > length(plate.start))
  stop(paste0('Error: The number of plates entered by the user is greater than the # of plates found in the data. ',
                 'User entered plates: ',num_384 + num_96,' Plates identified experimentally: ',length(plate.start)))
# Combine experimental data from multiple plates
exp_df <- do.call(rbind,exp_list)
Plate <- unlist(plate_list)
Plate_names <- unlist(plate_names_list)
#Add Plate # as a new column to the experimental data frame
exp_df <- exp_df %>% add_column(Plate,.after = 1)
exp_df <- exp_df %>% add_column(Plate_names,.after = 2)
```
We next read in the plate map data. If the number of plate maps provided does not match the number of experimental data, we have to expand the # of plate maps to match the data. We create a new unique id, taking secondaries and beadsets into account. If the user does not have duplicates in their plate map already, we create duplicates and arrange them horizontally or vertically.
```{r}
plate_data <- plater::read_plate(file = platemap_path,sep = ',')
num_plates <- ncol(plate_data) - 1
num_wells <- nrow(plate_data) 

# We are creating column names to account for the platemaps that are not represented in the platemap file due to different secondaries, beadsets, or duplicates
if (num_well_in_platemap == 384)
  {plate_data_cols <- rep(paste0('values.',c((num_plates + 1):num_384)))} 
if (num_well_in_platemap == 96 & num_384 != 0)
  {plate_data_cols <- rep(paste0('values.',c((num_plates + 1):(num_384*2))))}
if (num_well_in_platemap == 96 & num_96 != 0)
  {plate_data_cols <- rep(paste0('values.',c((num_plates + 1):num_96)))}

# Adds in empty columns to account for the plates that should be present
for(i in plate_data_cols)
  plate_data[,i] <- NA
# Initializes platemaps list and adds platemap data in an order that corresponds to the data key file
platemaps <- list()
for (i in platemap_list)
  platemaps <- append(platemaps,plate_data[i+1])

# Create new unique ids that include the bead set and secondary names. The various conditions account for the # of plates that were run experimentally if there were 96, 384 without duplicates, or 384 with duplicates
if (num_well_in_platemap == 384)
  {for (i in c(1:(num_384)))
    {plate_data[, i + 1] <- rep(paste0(platemaps[[i]],bead_names[i],secondary_names[i],sep = '.')) } }
if (num_well_in_platemap == 96 & num_96 != 0)
  {for (i in c(1:(num_96)))
    {plate_data[, i + 1] <- rep(paste0(platemaps[[i]],bead_names[i],secondary_names[i],sep = '.')) } }
if (num_well_in_platemap == 96 & num_384 != 0)
  {for (i in c(1:(2*num_384)))
    {plate_data[, i + 1] <- rep(paste0(platemaps[[i]],bead_names[i],secondary_names[i],sep = '.')) } }

# Accounts for duplicates by producing a tidy version of the sample to plate and well id mappings, taking into account duplicates
if (num_well_in_platemap == 96 & num_384 != 0)
  {colnames(plate_data) <- c('Well.ID',(1:ncol(plate_data)))
  plate_data_tidy <- plate_data %>% pivot_longer(names_to = "Plate",values_to = "unique_id",cols = -Well.ID)
  plate_ID_list <- list()
  for(i in c(1:(num_384)))
    {plate_ID_list[[i]] <- convert_to(plate_data_tidy,i,plate_names[i],(i*2-1),i*2,duplicate_horizontal,save_path)}
  new_plate_ID_list <- do.call(rbind,plate_ID_list)
  colnames(new_plate_ID_list) <- c("Plate","Well.ID","unique_id_edit")
}

# Convert plate data into a tidyr format if there are 384 wells in the platemap
if (num_well_in_platemap == 384)
  {colnames(plate_data) <- c('Well.ID',(1:ncol(plate_data)))
  plate_data_tidy <- plate_data %>% pivot_longer(names_to = "Plate",values_to = "unique_id_edit",cols = -Well.ID)}
```
We merge the plate data with the plate annotation and experimental data by using the unique_id, Plate, and Well.ID columns.
```{r}
if (num_well_in_platemap == 384 | num_well_in_platemap == 96 & num_96 != 0) 
  { # Split the unique_id_edit to get the unique_id, beadset, and secondary
  plate_data_tidier <- data.frame(do.call('rbind', strsplit(as.character(plate_data_tidy$unique_id_edit), '.', fixed=TRUE)))
  colnames(plate_data_tidier) <- c('unique_id','beadset','secondary')
  plate_data_tidyr <- cbind(plate_data_tidy,plate_data_tidier)
  # Filter out unique_id that are NA (we have to do this because of how the edited unique IDs are constructed)
  plate_data_tidyr <- plate_data_tidyr %>% dplyr::filter(unique_id != 'NA')
  # Well IDs and Sample Meta data are combined with left join to ensure controls are included within the combined data even if they are not found in the annotated meta data
  pre_combined_data <- left_join(plate_data_tidyr,sample_meta_data,by = "unique_id")
  combined_data <- merge(pre_combined_data,exp_df,by = c("Plate","Well.ID")) }

if (num_well_in_platemap == 96 & num_384 !=0) 
  { # Split the unique_id_edit to get the unique_id, beadset, and secondary
  plate_data_tidier <- data.frame(do.call('rbind', strsplit(as.character(new_plate_ID_list$unique_id_edit), '.', fixed=TRUE)))
  colnames(plate_data_tidier) <- c('unique_id','beadset','secondary')
  plate_data_tidyr <- cbind(new_plate_ID_list,plate_data_tidier)
  # Filter out unique_id that are NA (we have to do this because of how the edited unique IDs are constructed)
  plate_data_tidyr <- plate_data_tidyr %>% dplyr::filter(unique_id != 'NA')
  # Well IDs and Sample Meta data are combined with left join to ensure controls are included within the combined data even if they are not found in the annotated meta data
  pre_combined_data <- left_join(plate_data_tidyr,sample_meta_data,by = "unique_id")
  combined_data <- merge(pre_combined_data,exp_df,by = c("Plate","Well.ID")) }
```
We get data that passes the QC checks by mapping the bead count columns to the median columns and applying the QC check threshold that was previously defined. IF the corresponding bead count column is below the QC threshold, we mask or make the MFI column be a NA.
```{r}
# Getting the count and median columns separately
Count_col <- exp_df[,which(grepl("Count",colnames(exp_df)))]
Median_col <- exp_df[,which(grepl("Median",colnames(exp_df)))]
# Extracting the bead region # from the count and median columns
count_int <- gsub('.*Count.of.',"",colnames(Count_col))
median_int <- gsub('.*Median.BL2.H.of.',"",colnames(Median_col))
# Reordering the count columns so that it matches the ordering of the bead regions in the median columns
reorder_Count_col <- Count_col[,match(count_int,median_int)]
# Creating a logical matrix based on whether the bead counts are higher than the QC check provided by the user
mask <- ifelse(reorder_Count_col[,] > QC_min_bead_count, TRUE, FALSE)
# Extracting the MFI values that have bead counts over the thresholds
edited_Median_col <- replace(Median_col, !mask, NA)
# Merging the MFI values that passed QC checks with the Plate # and Well IDs
QC_exp_data <- cbind(Plate = exp_df$Plate,Well.ID = exp_df$Well.ID,edited_Median_col)
# Merging the experimental data that passes QC checks with the annotated data
QC_masked_data <- merge(pre_combined_data,QC_exp_data,by = c("Plate","Well.ID"))
```
We can extract particular measurements of interest if specified in the beginning.
```{r}
if (length(measurements) != 0)
  {combined_data_abbr <- select(combined_data,"unique_id","Plate","Well.ID",measurements)
  write.csv(combined_data_abbr, file=paste0(save_path,'combined_data_abbr_',exp_name,'.csv'))}
```
We can calculate summary statistics like the mean, median, and standard deviation for each sample (2 duplicates).
```{r}
summary_stats <- QC_masked_data %>% group_by(unique_id,Plate) %>% summarise(across(c((anno_col + 5):(ncol(QC_masked_data) -2)),list(mean = mean, median = median, sd = sd)))
summary_stats_edited <- merge(plate_data_tidyr,summary_stats,by = c('unique_id','Plate'))
summary_stats_editfed <- summary_stats_edited %>% dplyr::arrange(Plate) %>% dplyr::arrange(Well.ID)
summary_stats_edited <- summary_stats_edited %>% dplyr::select(-unique_id_edit)
```
We can check whether any data was lost or accidentally added while merging.
```{r}
check_dim_combined(plate_data_tidyr,pre_combined_data,combined_data,save_path,sample_meta_data,exp_df,anno_col,QC_exp_data,QC_masked_data,summary_stats,summary_stats_edited)
```
We finally save the combined, QC masked, and summary statistics edited data files.
```{r}
write.csv(combined_data, file=paste0(save_path,'combined_data_',exp_name,'.csv'))
write.csv(QC_masked_data, file=paste0(save_path,'QC_masked_combined_data_',exp_name,'.csv'))
write.csv(summary_stats_edited,file=paste0(save_path,'summary_stats',exp_name,'.csv'))
```
We can also correlation plots between duplicates for each sample if corr_plot is set to be TRUE.
```{r}
if(plot_corr) 
 {library(gridExtra)
  QC_exp_data_with_ids <- merge(plate_data_tidyr,QC_exp_data,by = c("Plate","Well.ID"))
  # Create a pdf of correlation plots
  p1<-c()
  i<-0
  # Initialize parameters
  platelist <- unique(QC_exp_data_with_ids$Plate)
  # for each feature
  for (plate_l in platelist){
    plotting_data <- QC_exp_data_with_ids[QC_exp_data_with_ids$Plate == plate_l,]
    idlist <- unique(plotting_data$unique_id)
    for (curfeat2 in idlist){
      curdata <- plotting_data[plotting_data$unique_id==curfeat2,]
      curdata2 <- pivot_longer(curdata,-c(1:6),names_to = 'measurement',values_to = 'value')
      curdata3 <- pivot_wider(curdata2,names_from = "Well.ID", values_from = "value")
      colnames(curdata3)[(ncol(curdata3)-1):ncol(curdata3)] <- c('duplicate_1','duplicate_2')
      if(all(is.na(c(curdata3$duplicate_1))) == FALSE & all(is.na(c(curdata3$duplicate_2))) == FALSE) 
      {i <- i+1
      p1[i] <- lapply(curfeat2, function(curfeat2) {  
        ggplot(data = curdata3, aes(x = duplicate_1, y = duplicate_2, colour = measurement)) + 
          geom_point(size=2) + geom_smooth(method = "lm", formula = duplicate_2 ~ duplicate_1, se=FALSE) + 
          geom_text(x = mean(range(curdata3$duplicate_1,na.rm = TRUE)), y = max(curdata3$duplicate_2,na.rm = TRUE), label = eq(curdata3$duplicate_1,curdata3$duplicate_2), parse = TRUE, colour = "black",size = 3 ) +
          theme(line = element_line(size=1),
                plot.title = element_text(hjust = 0.5)) +
          ggtitle(paste0("Unique_id: ",curfeat2, "     Plate: ",plate_l)) +
          theme(text = element_text(size= 10, hjust=0.5),
                title = element_text(size= 10, hjust=0.5),
                line = element_line(size=1),
                plot.title = element_text(hjust = 0.5)) +
          theme(legend.position="none",plot.title = element_text(hjust = 0.5)) } ) }  }
  }
  
  # Set filename of plot
  curfilname<-paste0(save_path,'correlation_plot.pdf')
  # Set row and column numbers and title
  ml <- marrangeGrob(p1, nrow=3, ncol=4, top="ptc")
  ggsave(curfilname, ml, width = 20, height = 10, dpi = 300, limitsize=FALSE)
  dev.off() }
```
We finally close the link to the logger file.
```{r}
sink(type = "message")
close(logger)
#closeAllConnections()
```
### Some Tips for Debugging
1) Use ```View()``` and ```str()``` to examine the structure of the data
2) Re-run individual lines of code to figure out where the error is occurring 
3) Use dim() to track dimensions if there seems to be an issue with dimensionality
4) Search Google 